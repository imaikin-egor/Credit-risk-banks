{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном ноутбуке представлены только модели участника команды, который получил наилучший результат на имеющихся данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y6Ct20CYp7sU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm, uniform, beta, lognorm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "pd.set_option('display.max_columns', None)\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#import optuna\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5dyU6MV_qyJS"
   },
   "outputs": [],
   "source": [
    "df_main = pd.read_excel('rating_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_ij0EZqAic1Y"
   },
   "outputs": [],
   "source": [
    "df_main.sort_values(['company', 'date'], inplace=True)\n",
    "df_main['default'] = df_main['default'].replace({'отозв.': 1, 'ликв.': 1}).astype(float)\n",
    "\n",
    "# Сброс индекса\n",
    "df_main.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mask = (df_main['default'].diff() == -1)\n",
    "\n",
    "same_company = df_main['company'] == df_main['company'].shift()\n",
    "\n",
    "result = df_main[mask & same_company]\n",
    "df_main = df_main.drop(result.index)\n",
    "\n",
    "df_main.sort_values(['company', 'date'], inplace=True)\n",
    "df_main.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d-nsYQ4Yi1DO"
   },
   "outputs": [],
   "source": [
    "df_main_finance = df_main[['date', 'company', 'number', 'net_assets', 'ROA', 'liquid', 'ibl',\n",
    "       'stocks', 'bond', 'oth_cap', 'sunk_retail_credit', 'NI',\n",
    "       'organization_credit', 'sunk_organization_credit', 'credit_portf',\n",
    "       'sunk_credit_portf', 'organization_deposit', 'retail_deposit',\n",
    "       'security_tot', 'ROE', 'retail_credit', 'reserv_credit_perc',\n",
    "       'zalog_credit_perc', 'foreign_na_fr', 'retail_deposit_fr', 'N3', 'N2',\n",
    "       'N1', 'capital', 'msk_spb', 'INF_SA', 'NX_growth', 'micex_std',\n",
    "       'miacr_std', 'miacr_amount', 'usd_rub_std_diff', 'micex_return',\n",
    "       'net_foreign_assets_diff', 'net_gov_debt_diff', 'other_fin_debt_diff',\n",
    "       'retail_debt_SA_DETREND_diff', 'stocks_capital_diff',\n",
    "       'i_retail_spread_diff', 'usd_rub_return', 'miacr_diff', 'default']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "srrrfPRDi1GO"
   },
   "outputs": [],
   "source": [
    "oot = df_main_finance[df_main_finance['date'] >= '2017-05']\n",
    "train = df_main_finance[df_main_finance['date'] < '2017-05']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "piMMEiiai1I_"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train.drop(['date', 'company', 'number', 'default'], axis=1),\n",
    "                                                  train.default,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xfiRMExi1QQ",
    "outputId": "550437c5-1345-477f-e282-759562171596"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC валид: 0.5666655440676255\n",
      "ROC-AUC тест: 0.5769476372924648\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = logreg.predict_proba(X_val)[:, 1]\n",
    "\n",
    "\n",
    "roc_auc_val = roc_auc_score(y_val, y_val_pred)\n",
    "print(f'ROC-AUC валид: {roc_auc_val}')\n",
    "\n",
    "\n",
    "y_oot_pred = logreg.predict_proba(oot.drop(['date', 'company', 'number', 'default'], axis=1))[:, 1]\n",
    "roc_auc_oot = roc_auc_score(oot.default, y_oot_pred)\n",
    "print(f'ROC-AUC тест: {roc_auc_oot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZE35PtbGz3A0",
    "outputId": "ea6b9b71-088b-4a24-abf3-4e8a0c72f048",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oot = df_main_finance[df_main_finance['date'] >= '2017-05']\n",
    "train = df_main_finance[df_main_finance['date'] < '2017-05']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train.drop(['date', 'company', 'number', 'default'], axis=1),\n",
    "                                                  train.default,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=42)\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "thresholds = sorted(xgb_model.feature_importances_, reverse=True)[25]\n",
    "sfm = SelectFromModel(xgb_model, threshold=thresholds)\n",
    "X_train_sfm = sfm.fit_transform(X_train, y_train)\n",
    "X_val_sfm = sfm.transform(X_val)\n",
    "\n",
    "\n",
    "xgb_model.fit(X_train_sfm, y_train, eval_set=[(X_val_sfm, y_val)], early_stopping_rounds=10, verbose=True)\n",
    "\n",
    "\n",
    "y_train_pred = xgb_model.predict_proba(X_train_sfm)[:, 1]\n",
    "\n",
    "# Вычисление ROC-AUC для обучающего набора данных\n",
    "\n",
    "\n",
    "y_val_pred = xgb_model.predict_proba(X_val_sfm)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_oot = oot.drop(['date', 'company', 'number', 'default'], axis=1)\n",
    "X_oot_sfm = sfm.transform(X_oot)\n",
    "y_oot_pred = xgb_model.predict_proba(X_oot_sfm)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "print(f'ROC-AUC обуч: {roc_auc_train}')\n",
    "roc_auc_val = roc_auc_score(y_val, y_val_pred)\n",
    "print(f'ROC-AUC валид: {roc_auc_val}')\n",
    "roc_auc_oot = roc_auc_score(oot.default, y_oot_pred)\n",
    "print(f'ROC-AUC тест: {roc_auc_oot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zwlB-aXC8-hr"
   },
   "outputs": [],
   "source": [
    "filename = 'model_fin.pkl'\n",
    "pickle.dump(xgb_model, open(filename, 'wb'))\n",
    "\n",
    "filename = 'sfm.pkl'\n",
    "pickle.dump(sfm, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXkmihXAHU4j",
    "outputId": "89bd9d4b-aa0d-4648-808b-21fb453850b9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importances = xgb_model.feature_importances_\n",
    "\n",
    "column_names = X_train.columns[sfm.get_support()]\n",
    "\n",
    "importance_data = sorted(zip(column_names, feature_importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for col_name, importance in importance_data[:30]:\n",
    "    print(f'Feature: {col_name}, Importance: {importance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Define the objective function\"\"\"\n",
    "\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
    "        'subsample': trial.suggest_loguniform('subsample', 0.01, 1.0),\n",
    "        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.01, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'use_label_encoder': False,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    optuna_model = XGBClassifier(**params)\n",
    "    optuna_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = optuna_model.predict_proba(X_val)\n",
    "\n",
    "    roc_auc = roc_auc_score(y_val, y_pred[:, 1])\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-20 23:46:07,434] A new study created in memory with name: no-name-0ac817eb-da70-4c79-997c-f158e4d1aa4c\n",
      "[I 2024-03-20 23:46:08,111] Trial 0 finished with value: 0.5748829690499444 and parameters: {'max_depth': 1, 'learning_rate': 0.022876653476122614, 'n_estimators': 209, 'min_child_weight': 1, 'gamma': 8.56004362165115e-06, 'subsample': 0.35348853734636254, 'colsample_bytree': 0.06885846484783337, 'reg_alpha': 0.002206102762049319, 'reg_lambda': 0.015682571761648896}. Best is trial 0 with value: 0.5748829690499444.\n",
      "[I 2024-03-20 23:46:08,321] Trial 1 finished with value: 0.5431583201427946 and parameters: {'max_depth': 6, 'learning_rate': 0.018076841499726517, 'n_estimators': 66, 'min_child_weight': 5, 'gamma': 0.028760196845221325, 'subsample': 0.023595033868409086, 'colsample_bytree': 0.18171712048299396, 'reg_alpha': 3.9430209426487994e-06, 'reg_lambda': 0.22091566271703836}. Best is trial 0 with value: 0.5748829690499444.\n",
      "[I 2024-03-20 23:46:09,040] Trial 2 finished with value: 0.5838749873707607 and parameters: {'max_depth': 4, 'learning_rate': 0.20704533021620813, 'n_estimators': 297, 'min_child_weight': 4, 'gamma': 3.7559347637614605e-07, 'subsample': 0.08743722277053166, 'colsample_bytree': 0.02069214393833387, 'reg_alpha': 1.715854427010869e-05, 'reg_lambda': 4.5740529729318136e-08}. Best is trial 2 with value: 0.5838749873707607.\n",
      "[I 2024-03-20 23:46:10,956] Trial 3 finished with value: 0.7892769339574984 and parameters: {'max_depth': 9, 'learning_rate': 0.04158503649535325, 'n_estimators': 228, 'min_child_weight': 3, 'gamma': 0.16998916407932263, 'subsample': 0.5165639535151527, 'colsample_bytree': 0.7503043813724244, 'reg_alpha': 1.1079462823290217e-06, 'reg_lambda': 0.0008656257088947986}. Best is trial 3 with value: 0.7892769339574984.\n",
      "[I 2024-03-20 23:46:11,223] Trial 4 finished with value: 0.561563331424915 and parameters: {'max_depth': 4, 'learning_rate': 0.6584738073994729, 'n_estimators': 86, 'min_child_weight': 4, 'gamma': 7.032463089867579e-06, 'subsample': 0.042624135353107835, 'colsample_bytree': 0.23637244653882317, 'reg_alpha': 1.977457865188817e-05, 'reg_lambda': 2.7484203496374848e-08}. Best is trial 3 with value: 0.7892769339574984.\n",
      "[I 2024-03-20 23:46:12,247] Trial 5 finished with value: 0.5 and parameters: {'max_depth': 8, 'learning_rate': 0.18389130083015656, 'n_estimators': 490, 'min_child_weight': 10, 'gamma': 3.849008402350521e-05, 'subsample': 0.018018860690746995, 'colsample_bytree': 0.05670553821525192, 'reg_alpha': 0.009627542358838424, 'reg_lambda': 2.3662771002456483e-08}. Best is trial 3 with value: 0.7892769339574984.\n",
      "[I 2024-03-20 23:46:13,742] Trial 6 finished with value: 0.6533863200080827 and parameters: {'max_depth': 3, 'learning_rate': 0.01871010001121948, 'n_estimators': 402, 'min_child_weight': 8, 'gamma': 0.30448123849499, 'subsample': 0.3599384974795032, 'colsample_bytree': 0.9059153804742887, 'reg_alpha': 0.06294423882911886, 'reg_lambda': 0.010979202118367974}. Best is trial 3 with value: 0.7892769339574984.\n",
      "[I 2024-03-20 23:46:14,009] Trial 7 finished with value: 0.5 and parameters: {'max_depth': 1, 'learning_rate': 0.21149135549535644, 'n_estimators': 67, 'min_child_weight': 6, 'gamma': 5.13685470081318e-07, 'subsample': 0.019090339914111413, 'colsample_bytree': 0.3192219978891256, 'reg_alpha': 0.0009657122641934323, 'reg_lambda': 6.1630579914140815e-06}. Best is trial 3 with value: 0.7892769339574984.\n",
      "[I 2024-03-20 23:46:15,548] Trial 8 finished with value: 0.6559458458222477 and parameters: {'max_depth': 3, 'learning_rate': 0.010636928385010732, 'n_estimators': 425, 'min_child_weight': 4, 'gamma': 0.5334313662378704, 'subsample': 0.5396723678218545, 'colsample_bytree': 0.7705086355557311, 'reg_alpha': 1.3575312734857531e-05, 'reg_lambda': 1.319366898235364e-06}. Best is trial 3 with value: 0.7892769339574984.\n",
      "[I 2024-03-20 23:46:15,936] Trial 9 finished with value: 0.5 and parameters: {'max_depth': 4, 'learning_rate': 0.34449604894200725, 'n_estimators': 168, 'min_child_weight': 5, 'gamma': 0.018192276879051096, 'subsample': 0.011125542804649838, 'colsample_bytree': 0.12722583968898787, 'reg_alpha': 0.10544948529494479, 'reg_lambda': 0.578793276687616}. Best is trial 3 with value: 0.7892769339574984.\n",
      "[I 2024-03-20 23:46:17,933] Trial 10 finished with value: 0.8074630384265651 and parameters: {'max_depth': 9, 'learning_rate': 0.05851835616314303, 'n_estimators': 296, 'min_child_weight': 1, 'gamma': 0.0015478036789368793, 'subsample': 0.9826273368607821, 'colsample_bytree': 0.0101205470444365, 'reg_alpha': 1.788722038248376e-08, 'reg_lambda': 0.00027762302591893037}. Best is trial 10 with value: 0.8074630384265651.\n",
      "[I 2024-03-20 23:46:19,955] Trial 11 finished with value: 0.8091806149597548 and parameters: {'max_depth': 9, 'learning_rate': 0.05967988601394193, 'n_estimators': 303, 'min_child_weight': 1, 'gamma': 0.0016228946911716325, 'subsample': 0.9470352098444895, 'colsample_bytree': 0.0115855131025056, 'reg_alpha': 1.4530122502856077e-08, 'reg_lambda': 0.0004090059013383458}. Best is trial 11 with value: 0.8091806149597548.\n",
      "[I 2024-03-20 23:46:21,578] Trial 12 finished with value: 0.806789479001785 and parameters: {'max_depth': 7, 'learning_rate': 0.06753369900387254, 'n_estimators': 315, 'min_child_weight': 2, 'gamma': 0.0013337243298940254, 'subsample': 0.99872211184946, 'colsample_bytree': 0.010330712517865537, 'reg_alpha': 1.717859080732456e-08, 'reg_lambda': 6.375014031375647e-05}. Best is trial 11 with value: 0.8091806149597548.\n",
      "[I 2024-03-20 23:46:23,354] Trial 13 finished with value: 0.6455056747381537 and parameters: {'max_depth': 9, 'learning_rate': 0.07158182428724218, 'n_estimators': 341, 'min_child_weight': 1, 'gamma': 0.0006056294403340965, 'subsample': 0.16966205485751423, 'colsample_bytree': 0.02380646580055336, 'reg_alpha': 1.0895668157548567e-08, 'reg_lambda': 0.0002654326801305151}. Best is trial 11 with value: 0.8091806149597548.\n",
      "[I 2024-03-20 23:46:25,471] Trial 14 finished with value: 0.7701141683225002 and parameters: {'max_depth': 7, 'learning_rate': 0.04365894351096526, 'n_estimators': 378, 'min_child_weight': 2, 'gamma': 0.0011465287177878389, 'subsample': 0.9689909617747118, 'colsample_bytree': 0.010290053817936289, 'reg_alpha': 2.8602036327306993e-07, 'reg_lambda': 1.5577118011664544e-05}. Best is trial 11 with value: 0.8091806149597548.\n",
      "[I 2024-03-20 23:46:26,353] Trial 15 finished with value: 0.5748829690499444 and parameters: {'max_depth': 8, 'learning_rate': 0.1056941981045798, 'n_estimators': 247, 'min_child_weight': 7, 'gamma': 2.026095314773334e-08, 'subsample': 0.1607587308357614, 'colsample_bytree': 0.025312273276164175, 'reg_alpha': 1.2248298000261406e-07, 'reg_lambda': 0.002336243144589931}. Best is trial 11 with value: 0.8091806149597548.\n",
      "[I 2024-03-20 23:46:27,488] Trial 16 finished with value: 0.7385915872427845 and parameters: {'max_depth': 9, 'learning_rate': 0.11583498105226159, 'n_estimators': 188, 'min_child_weight': 1, 'gamma': 0.009555375090338306, 'subsample': 0.24499478942683864, 'colsample_bytree': 0.04214481797359094, 'reg_alpha': 9.900082095554615e-08, 'reg_lambda': 5.132686279051446e-07}. Best is trial 11 with value: 0.8091806149597548.\n",
      "[I 2024-03-20 23:46:28,070] Trial 17 finished with value: 0.5273296736604587 and parameters: {'max_depth': 6, 'learning_rate': 0.0404323123302899, 'n_estimators': 131, 'min_child_weight': 3, 'gamma': 0.00011398317610263979, 'subsample': 0.0767441570275197, 'colsample_bytree': 0.01779372633028389, 'reg_alpha': 0.00011478506591238976, 'reg_lambda': 7.636020926159462e-05}. Best is trial 11 with value: 0.8091806149597548.\n",
      "[I 2024-03-20 23:46:29,764] Trial 18 finished with value: 0.7655676422052334 and parameters: {'max_depth': 8, 'learning_rate': 0.06458642986548047, 'n_estimators': 271, 'min_child_weight': 2, 'gamma': 0.0032363142033253146, 'subsample': 0.6233487595269775, 'colsample_bytree': 0.03736640139586463, 'reg_alpha': 8.50229746043159e-07, 'reg_lambda': 0.026125203349363555}. Best is trial 11 with value: 0.8091806149597548.\n",
      "[I 2024-03-20 23:46:30,847] Trial 19 finished with value: 0.7575186070791096 and parameters: {'max_depth': 7, 'learning_rate': 0.8040990350838777, 'n_estimators': 357, 'min_child_weight': 10, 'gamma': 0.0002497844806098428, 'subsample': 0.67079394966514, 'colsample_bytree': 0.015748397301900842, 'reg_alpha': 3.456951748794276e-08, 'reg_lambda': 0.0024236642484639277}. Best is trial 11 with value: 0.8091806149597548.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 9, 'learning_rate': 0.05967988601394193, 'n_estimators': 303, 'min_child_weight': 1, 'gamma': 0.0016228946911716325, 'subsample': 0.9470352098444895, 'colsample_bytree': 0.0115855131025056, 'reg_alpha': 1.4530122502856077e-08, 'reg_lambda': 0.0004090059013383458}\n",
      "Best GINI: 0.8091806149597548\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters:', study.best_params)\n",
    "print('Best GINI:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_model2 = XGBClassifier(**study.best_params)\n",
    "xgb_model2.fit(X_train, y_train)\n",
    "\n",
    "thresholds2 = sorted(xgb_model2.feature_importances_, reverse=True)[25]\n",
    "sfm2 = SelectFromModel(xgb_model2, threshold=thresholds)\n",
    "X_train_sfm2 = sfm2.fit_transform(X_train, y_train)\n",
    "X_val_sfm2 = sfm2.transform(X_val)\n",
    "\n",
    "\n",
    "xgb_model2.fit(X_train_sfm2, y_train, eval_set=[(X_val_sfm2, y_val)], early_stopping_rounds=10, verbose=True)\n",
    "\n",
    "\n",
    "y_train_pred = xgb_model2.predict_proba(X_train_sfm2)[:, 1]\n",
    "y_val_pred = xgb_model2.predict_proba(X_val_sfm2)[:, 1]\n",
    "\n",
    "X_oot = oot.drop(['date', 'company', 'number', 'default'], axis=1)\n",
    "X_oot_sfm2 = sfm2.transform(X_oot)\n",
    "y_oot_pred = xgb_model2.predict_proba(X_oot_sfm2)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_train = roc_auc_score(y_train, y_train_pred)\n",
    "print(f'ROC-AUC обуч: {roc_auc_train}')\n",
    "roc_auc_val = roc_auc_score(y_val, y_val_pred)\n",
    "print(f'ROC-AUC валид: {roc_auc_val}')\n",
    "roc_auc_oot = roc_auc_score(oot.default, y_oot_pred)\n",
    "print(f'ROC-AUC тест: {roc_auc_oot}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизация гиперпараметров с помощью Optuna не улучшила результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "Cz9Ld8FqJPde",
    "outputId": "a6ec2bb9-3f6f-4151-b23c-a46e078105c9"
   },
   "outputs": [],
   "source": [
    "df_feature_importances = pd.DataFrame({\"feature\": column_names, \"importance\": feature_importances}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "# Построить график\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=df_feature_importances[:30], x=\"importance\", y=\"feature\")\n",
    "plt.title(\"Feature importance, GBC\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wTjEgEnyKE7c",
    "outputId": "df1bcd5e-6c9d-46a5-a040-4afcf97cff66"
   },
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(xgb_model)\n",
    "shap_values = explainer(X_train_sfm)\n",
    "\n",
    "shap.plots.beeswarm(shap_values=shap_values, plot_size=(15, 8))\n",
    "\n",
    "shap.plots.waterfall(shap_values[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration = df_main_finance[(df_main_finance['date'] < '2017-05') & (df_main_finance['date'] >= '2017-02')]\n",
    "\n",
    "X_calibration = calibration.drop(['date', 'company', 'number', 'default'], axis=1)\n",
    "X_calibration_sfm = sfm.transform(X_calibration)\n",
    "\n",
    "\n",
    "y_calibration = calibration['default']\n",
    "\n",
    "proba_calibration = xgb_model.predict_proba(X_calibration_sfm)[:, 1]\n",
    "\n",
    "isotonic = IsotonicRegression(y_min=0, y_max=1, out_of_bounds='clip')\n",
    "isotonic.fit(proba_calibration, y_calibration)\n",
    "\n",
    "proba_isotonic = isotonic.predict(xgb_model.predict_proba(X_oot_sfm)[:, 1])\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(proba_calibration.reshape(-1, 1), y_calibration)\n",
    "\n",
    "proba_logistic = logistic.predict_proba(xgb_model.predict_proba(X_oot_sfm)[:, 1].reshape(-1, 1))[:, 1]\n",
    "\n",
    "\n",
    "def expected_calibration_error(y, proba, bins = 'fd'):\n",
    "  bin_count, bin_edges = np.histogram(proba, bins = bins)\n",
    "  n_bins = len(bin_count)\n",
    "  bin_edges[0] -= 1e-8 # because left edge is not included\n",
    "  bin_id = np.digitize(proba, bin_edges, right = True) - 1\n",
    "  bin_ysum = np.bincount(bin_id, weights = y, minlength = n_bins)\n",
    "  bin_probasum = np.bincount(bin_id, weights = proba, minlength = n_bins)\n",
    "  bin_ymean = np.divide(bin_ysum, bin_count, out = np.zeros(n_bins), where = bin_count > 0)\n",
    "  bin_probamean = np.divide(bin_probasum, bin_count, out = np.zeros(n_bins), where = bin_count > 0)\n",
    "  ece = np.abs((bin_probamean - bin_ymean) * bin_count).sum() / len(proba)\n",
    "  return ece\n",
    "\n",
    "exp_cal_er_xg = expected_calibration_error(oot.default, xgb_model.predict_proba(X_oot_sfm)[:, 1])\n",
    "print('ECE откалиброванной модели XGBoost на ООТ = ' + str(round(exp_cal_er_xg, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train.drop(['date', 'company', 'number', 'default'], axis=1),\n",
    "                                                  train.default,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=42)\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "thresholds = sorted(xgb_model.feature_importances_, reverse=True)[25]\n",
    "sfm = SelectFromModel(xgb_model, threshold=thresholds)\n",
    "X_train_sfm = sfm.fit_transform(X_train, y_train)\n",
    "X_val_sfm = sfm.transform(X_val)\n",
    "\n",
    "\n",
    "xgb_model.fit(X_train_sfm, y_train, eval_set=[(X_val_sfm, y_val)], early_stopping_rounds=10, verbose=True)\n",
    "\n",
    "\n",
    "y_train_pred = xgb_model.predict_proba(X_train_sfm)[:, 1]\n",
    "\n",
    "# Вычисление ROC-AUC для обучающего набора данных\n",
    "\n",
    "\n",
    "y_val_pred = xgb_model.predict_proba(X_val_sfm)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_oot = oot.drop(['date', 'company', 'number', 'default'], axis=1)\n",
    "X_oot_sfm = sfm.transform(X_oot)\n",
    "oot['pd'] = xgb_model.predict_proba(X_oot_sfm)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Расчет для 6 задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "avangard_bank = oot[oot['number'] == 2879]\n",
    "expo_bank = oot[oot['number'] == 2998]\n",
    "ros_bank = oot[oot['number'] == 2272]\n",
    "alpha_bank = oot[oot['number'] == 1326]\n",
    "loko_bank = oot[oot['number'] == 2707]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Горизонт 1 год"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>50%</th>\n",
       "      <th>99.9%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>36315600.0</td>\n",
       "      <td>5.050702e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240000000.0</td>\n",
       "      <td>320000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean           std  min  50%        99.9%          max\n",
       "Loss  1000000.0  36315600.0  5.050702e+07  0.0  0.0  240000000.0  320000000.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_simulations = 1000000\n",
    "\n",
    "lgd=0.4\n",
    "\n",
    "PD = [1 - (1 - avangard_bank.iloc[-1]['pd']**4),\n",
    "      1 - (1 - expo_bank.iloc[-1]['pd'])**4,\n",
    "      1 - (1 - ros_bank.iloc[-1]['pd'])**4,\n",
    "      1 - (1 - alpha_bank.iloc[-1]['pd'])**4,\n",
    "      1 - (1 - loko_bank.iloc[-1]['pd'])**4]\n",
    "\n",
    "avangard_loss = np.random.binomial(n=1, p=PD[0], size=[n_simulations]) * 200000000 * lgd\n",
    "expobank_loss = np.random.binomial(n=1, p=PD[1], size=[n_simulations]) * 200000000 * lgd\n",
    "rosbank_loss = np.random.binomial(n=1, p=PD[2], size=[n_simulations]) * 200000000 * lgd\n",
    "alfabank_loss = np.random.binomial(n=1, p=PD[3], size=[n_simulations]) * 200000000 * lgd\n",
    "lokobank_loss = np.random.binomial(n=1, p=PD[4], size=[n_simulations]) * 200000000 * lgd\n",
    "\n",
    "total_loss = map(sum, zip(avangard_loss, expobank_loss, rosbank_loss, alfabank_loss, lokobank_loss))\n",
    "\n",
    "loss_df = pd.DataFrame({'Loss': list(total_loss)}).sort_values(by='Loss', ascending=False)\n",
    "loss_df.describe(percentiles=[0.999]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Горизонт 5 лет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avangard_bank' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m n_simulations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000000\u001b[39m\n\u001b[1;32m      3\u001b[0m lgd\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m\n\u001b[0;32m----> 5\u001b[0m PD5 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mavangard_bank\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpd\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m),\n\u001b[1;32m      6\u001b[0m       \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m expo_bank\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpd\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      7\u001b[0m       \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ros_bank\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpd\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      8\u001b[0m       \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha_bank\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpd\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      9\u001b[0m       \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m loko_bank\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpd\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m]\n\u001b[1;32m     11\u001b[0m avangard_loss5 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mbinomial(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, p\u001b[38;5;241m=\u001b[39mPD5[\u001b[38;5;241m0\u001b[39m], size\u001b[38;5;241m=\u001b[39m[n_simulations]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m200000000\u001b[39m \u001b[38;5;241m*\u001b[39m lgd\n\u001b[1;32m     12\u001b[0m expobank_loss5 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mbinomial(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, p\u001b[38;5;241m=\u001b[39mPD5[\u001b[38;5;241m1\u001b[39m], size\u001b[38;5;241m=\u001b[39m[n_simulations]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m200000000\u001b[39m \u001b[38;5;241m*\u001b[39m lgd\n",
      "\u001b[0;31mNameError\u001b[0m: name 'avangard_bank' is not defined"
     ]
    }
   ],
   "source": [
    "n_simulations = 1000000\n",
    "\n",
    "lgd=0.4\n",
    "\n",
    "PD5 = [1 - (1 - avangard_bank.iloc[-1]['pd']**20),\n",
    "      1 - (1 - expo_bank.iloc[-1]['pd'])**20,\n",
    "      1 - (1 - ros_bank.iloc[-1]['pd'])**20,\n",
    "      1 - (1 - alpha_bank.iloc[-1]['pd'])**20,\n",
    "      1 - (1 - loko_bank.iloc[-1]['pd'])**20]\n",
    "\n",
    "avangard_loss5 = np.random.binomial(n=1, p=PD5[0], size=[n_simulations]) * 200000000 * lgd\n",
    "expobank_loss5 = np.random.binomial(n=1, p=PD5[1], size=[n_simulations]) * 200000000 * lgd\n",
    "rosbank_loss5 = np.random.binomial(n=1, p=PD5[2], size=[n_simulations]) * 200000000 * lgd\n",
    "alfabank_loss5 = np.random.binomial(n=1, p=PD5[3], size=[n_simulations]) * 200000000 * lgd\n",
    "lokobank_loss5 = np.random.binomial(n=1, p=PD5[4], size=[n_simulations]) * 200000000 * lgd\n",
    "\n",
    "total_loss5 = map(sum, zip(avangard_loss5, expobank_loss5, rosbank_loss5, alfabank_loss5, lokobank_loss5))\n",
    "loss_df = pd.DataFrame({'Loss': list(total_loss5)}).sort_values(by='Loss', ascending=False)\n",
    "loss_df.describe(percentiles=[0.999]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание b вариант 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maturity_slope(pd, a=0.11852, b=-0.05478):\n",
    "    \"\"\"\n",
    "        DESCRIPTION:\n",
    "        ------------\n",
    "        Credit portfolios consist of instruments with different maturities. Both intuition and\n",
    "        empirical evidence indicate that long-term credits are riskier than short-term credits. As a\n",
    "        consequence, the capital requirement should increase with maturity.\n",
    "\n",
    "        In order to derive the Basel maturity adjustment function, the grid of relative VaR figures\n",
    "        (in relation to 2.5 years maturity) was smoothed by a statistical regression model.\n",
    "        This includes the slope of the adjustment function with respect to M decreases as\n",
    "        the PD increases.\n",
    "\n",
    "        REFERENCE:\n",
    "        ----------\n",
    "        https://www.bis.org/bcbs/irbriskweight.pdf\n",
    "        4.6. Maturity adjustments\n",
    "\n",
    "        PARAMS:\n",
    "        -------\n",
    "        :param pd: array of PDs from portfolio\n",
    "        :param a: slope adjustment coefficient 1\n",
    "        :param b: slope adjustement coefficient 2\n",
    "        :return maturity_slope: array of Smoothed (regression) maturity adjustment (smoothed over PDs)\n",
    "    \"\"\"\n",
    "    return np.power((a + b * np.log(pd)), 2)\n",
    "\n",
    "\n",
    "def get_maturity_adjusment(pd, m, y=2.5):\n",
    "    \"\"\"\n",
    "        DESCRIPTION:\n",
    "        ------------\n",
    "        Maturity adjustments are the ratios of each of these VaR figures to the VaR\n",
    "        of a “standard” maturity, which was set at 2.5 years, for each maturity and each rating grade.\n",
    "\n",
    "        REFERENCE:\n",
    "        ----------\n",
    "        https://www.bis.org/bcbs/irbriskweight.pdf\n",
    "        4.6. Maturity adjustments\n",
    "\n",
    "        PARAMS:\n",
    "        -------\n",
    "        :param pd: array of PDs from portfolio\n",
    "        :param tenor: array of tenors from portfolio or remaining term to maturity\n",
    "        :param y: standard maturity, 2.5 years\n",
    "        :return maturity_adj: array of maturity adjustments used in risk-capital allocation\n",
    "    \"\"\"\n",
    "    slope = get_maturity_slope(pd)\n",
    "    return np.divide(1 + (m - y) * slope, 1 - 1.5 * slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_simulations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;66;03m#maturity adjustment\u001b[39;00m\n\u001b[1;32m      5\u001b[0m maturity_adj \u001b[38;5;241m=\u001b[39m get_maturity_adjusment(pd_array, m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.5\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m avangard_loss5 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mbinomial(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, p\u001b[38;5;241m=\u001b[39mPD5[\u001b[38;5;241m0\u001b[39m], size\u001b[38;5;241m=\u001b[39m[\u001b[43mn_simulations\u001b[49m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m200000000\u001b[39m \u001b[38;5;241m*\u001b[39m lgd \u001b[38;5;241m*\u001b[39m maturity_adj[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m expobank_loss5 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mbinomial(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, p\u001b[38;5;241m=\u001b[39mPD5[\u001b[38;5;241m1\u001b[39m], size\u001b[38;5;241m=\u001b[39m[n_simulations]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m200000000\u001b[39m \u001b[38;5;241m*\u001b[39m lgd \u001b[38;5;241m*\u001b[39m maturity_adj[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      8\u001b[0m rosbank_loss5 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mbinomial(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, p\u001b[38;5;241m=\u001b[39mPD5[\u001b[38;5;241m2\u001b[39m], size\u001b[38;5;241m=\u001b[39m[n_simulations]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m200000000\u001b[39m \u001b[38;5;241m*\u001b[39m lgd \u001b[38;5;241m*\u001b[39m maturity_adj[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_simulations' is not defined"
     ]
    }
   ],
   "source": [
    "pd_array = np.array(PD5)\n",
    "\n",
    "m = 5 #maturity adjustment\n",
    "\n",
    "maturity_adj = get_maturity_adjusment(pd_array, m, y=2.5)\n",
    "avangard_loss5 = np.random.binomial(n=1, p=PD5[0], size=[n_simulations]) * 200000000 * lgd * maturity_adj[0]\n",
    "expobank_loss5 = np.random.binomial(n=1, p=PD5[1], size=[n_simulations]) * 200000000 * lgd * maturity_adj[1]\n",
    "rosbank_loss5 = np.random.binomial(n=1, p=PD5[2], size=[n_simulations]) * 200000000 * lgd * maturity_adj[2]\n",
    "alfabank_loss5 = np.random.binomial(n=1, p=PD5[3], size=[n_simulations]) * 200000000 * lgd * maturity_adj[3]\n",
    "lokobank_loss5 = np.random.binomial(n=1, p=PD5[4], size=[n_simulations]) * 200000000 * lgd * maturity_adj[4]\n",
    "\n",
    "total_loss5 = map(sum, zip(avangard_loss5, expobank_loss5, rosbank_loss5, alfabank_loss5, lokobank_loss5))\n",
    "loss_df = pd.DataFrame({'Loss': list(total_loss5)}).sort_values(by='Loss', ascending=False)\n",
    "loss_df.describe(percentiles=[0.999]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание b вариант 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rho_asset_correlation(pd, k_factor=-50, rho_min=0.12, rho_max=0.24):\n",
    "    \"\"\"\n",
    "        DESCRIPTION:\n",
    "        -----------\n",
    "        The single systematic risk factor needed in the ASRF model may be interpreted as reflecting\n",
    "        the state of the global economy. The degree of the obligor’s exposure to the systematic risk\n",
    "        factor is expressed by the asset correlation. The asset correlations, in short, show how the\n",
    "        asset value (e.g. sum of all asset values of a firm) of one borrower depends on the asset\n",
    "        value of another borrower.\n",
    "\n",
    "        The asset correlation function is built of two limit correlations of 12% and 24% for very\n",
    "        high and very low PDs (100% and 0%, respectively). Correlations between these limits are\n",
    "        modelled by an exponential weighting function that displays the dependency on PD. The\n",
    "        exponential function decreases rather fast; its pace is determined by the so-called\n",
    "        “k-factor”, which is set at 50 for corporate exposures.\n",
    "\n",
    "        REFERENCE:\n",
    "        ----------\n",
    "        https://www.bis.org/bcbs/irbriskweight.pdf\n",
    "        5.2. Supervisory estimates of asset correlations for corporate, bank and sovereign exposures\n",
    "\n",
    "        PARAMS:\n",
    "        -------\n",
    "        :param pd: arrays of PDs from portfolio\n",
    "        :param k_factor: Set to 50 for corporates exposures\n",
    "        :param rho_min: 12% min limit, for PDs = 100%\n",
    "        :param rho_max: 14% max limit, for PDs = 0%\n",
    "        :return rho: array of assets correlation\n",
    "    \"\"\"\n",
    "    exponential_weights = np.divide((1 - np.exp(k_factor * pd)), (1 - np.exp(k_factor)))\n",
    "    return rho_min * exponential_weights + rho_max * (1 - exponential_weights)\n",
    "\n",
    "def conditional_pd(pd, rho, y):\n",
    "    \"\"\"\n",
    "        DESCRIPTION:\n",
    "        ------------\n",
    "        The Vasicek model is a one period default model, i.e., loss only occurs when an \n",
    "        obligor defaults in a fixed time horizon. Based on Merton‘s firm-value model, to describe \n",
    "        the obligor’s default and its correlation structure, we assign each obligor a random\n",
    "        variable called firm-value.\n",
    "\n",
    "        The firm-value of obligor n is represented by a common, standard normally distributed factor\n",
    "        Y component and an idiosyncratic standard normal noise component n.\n",
    "        The Y factor is the state of the world or business cycle, usually called systematic factor.\n",
    "\n",
    "        The probability of default of obligor n conditional to a realization of Y = y is given by\n",
    "        this function.\n",
    "\n",
    "        REFERENCE:\n",
    "        ----------\n",
    "        https://core.ac.uk/download/pdf/41778167.pdf\n",
    "\n",
    "        PARAMS:\n",
    "        -------\n",
    "        :param pd: probability of default of obligor n\n",
    "        :param rho: asset correlation, to be computed from IRB approach\n",
    "        :param y: The Y factor is the state of the world or business cycle, usually called\n",
    "        systematic factor.\n",
    "        :return pd_conditional: conditional probability of default of obligor n to a realization of\n",
    "        Y.\n",
    "    \"\"\"\n",
    "\n",
    "    numerator = np.subtract(norm.ppf(pd), np.multiply(np.sqrt(rho), y))\n",
    "    denominator = np.sqrt(1 - rho)\n",
    "    return norm.cdf(np.divide(numerator, denominator))\n",
    "\n",
    "\n",
    "def run_simulation(pd, ead, lgd, m, num_simulations=1000):\n",
    "    \"\"\"\n",
    "        DESCRIPTION:\n",
    "        ------------\n",
    "        This functions runs a montecarlo simulation\n",
    "\n",
    "        1) y is randomly generated from a normal distribution\n",
    "        2) we generate a uniform continuous random variable\n",
    "        3) we compare the random variable to pd to define if default there is\n",
    "        4) if default compute loss = default_indicator * EAD * LGD * ma\n",
    "        5) aggregate all losses\n",
    "        PARAMS:\n",
    "        -------\n",
    "        :param pd: probability of default\n",
    "        :param ead: exposure at risk\n",
    "        :param lgd: loss given default\n",
    "        :param num_simulations: number of simulation/iteration to be performed\n",
    "        :return scenario_losses: array of losses\n",
    "    \"\"\"\n",
    "    scenario_losses = np.array([])\n",
    "    rho = get_rho_asset_correlation(pd)\n",
    "    maturity_adj = get_maturity_adjusment(pd, m, y=2.5)\n",
    "    for _ in range(num_simulations):\n",
    "        y = np.random.normal(size=1)\n",
    "        pd_cond = conditional_pd(pd, rho, y)\n",
    "        uniform_random_variable = uniform.rvs(size=pd.size)\n",
    "        default_indicator = (uniform_random_variable < pd_cond) * 1.0\n",
    "        loss = default_indicator * ead * lgd * maturity_adj\n",
    "        total_loss = loss.sum()\n",
    "        scenario_losses = np.concatenate([scenario_losses, np.array([total_loss])])\n",
    "    return scenario_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PD5 = [0.1, 0.52982909, 0.53439636, 0.34748718, 0.37568186]\n",
    "rho = get_rho_asset_correlation(PD5)\n",
    "rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ead=200000000\n",
    "scenario_losses = run_simulation(pd_array, ead, lgd, m, 100)\n",
    "scenario_losses = np.mean(scenario_losses)\n",
    "var_999 = np.percentile(scenario_losses, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145377806.66063532"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (0,) (5,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m rho \u001b[38;5;241m=\u001b[39m get_rho_asset_correlation(pd_array)\n\u001b[0;32m----> 2\u001b[0m WCDR \u001b[38;5;241m=\u001b[39m norm\u001b[38;5;241m.\u001b[39mcdf(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mrho\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mppf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPD\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(rho\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mrho)) \u001b[38;5;241m*\u001b[39m norm\u001b[38;5;241m.\u001b[39mppf(\u001b[38;5;241m0.999\u001b[39m))\n\u001b[1;32m      3\u001b[0m K \u001b[38;5;241m=\u001b[39m (WCDR \u001b[38;5;241m-\u001b[39m PD) \u001b[38;5;241m*\u001b[39m lgd \u001b[38;5;241m*\u001b[39m ead \n\u001b[1;32m      4\u001b[0m K\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (0,) (5,) "
     ]
    }
   ],
   "source": [
    "rho = get_rho_asset_correlation(pd_array)\n",
    "WCDR = norm.cdf(np.sqrt(1/(1-rho)) * norm.ppf(PD) + np.sqrt(rho/(1-rho)) * norm.ppf(0.999))\n",
    "K = (WCDR - PD) * lgd * ead \n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103490071.17581475"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_array = [1.3963097936775526e-06,\n",
    " 0.14009366093479736,\n",
    " 0.1417708275062729,\n",
    " 0.08184118064241586,\n",
    " 0.08991660534671952]\n",
    "lgd = 0.4\n",
    "ead = 200000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3963097936775526e-06,\n",
       " 0.14009366093479736,\n",
       " 0.1417708275062729,\n",
       " 0.08184118064241586,\n",
       " 0.08991660534671952]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = [0.12, 0.200238562, 0.202498572, 0.163330245, 0.17687558]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_random = [0.5, 0.31, 0.2, 0.5, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho = get_rho_asset_correlation(pd_random)\n",
    "rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
